[2023-06-14T19:26:39.820+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:26:39.834+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:26:39.837+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:26:39.860+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:26:39.873+0000] {standard_task_runner.py:57} INFO - Started process 8921 to run task
[2023-06-14T19:26:39.880+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1586', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp_yh9d_1i']
[2023-06-14T19:26:39.884+0000] {standard_task_runner.py:85} INFO - Job 1586: Subtask wait_for_json
[2023-06-14T19:26:39.961+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:26:40.099+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:26:40.116+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:26:40.142+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:26:40.175+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:26:40.215+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:27:12.068+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:27:12.096+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:27:12.099+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:27:12.141+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:27:12.172+0000] {standard_task_runner.py:57} INFO - Started process 8939 to run task
[2023-06-14T19:27:12.187+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1589', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpq61qdfz3']
[2023-06-14T19:27:12.193+0000] {standard_task_runner.py:85} INFO - Job 1589: Subtask wait_for_json
[2023-06-14T19:27:12.327+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:27:12.438+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:27:12.455+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:27:12.482+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:27:12.515+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:27:12.561+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:27:43.553+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:27:43.567+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:27:43.568+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:27:43.587+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:27:43.596+0000] {standard_task_runner.py:57} INFO - Started process 8957 to run task
[2023-06-14T19:27:43.603+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1592', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp0szihg7n']
[2023-06-14T19:27:43.606+0000] {standard_task_runner.py:85} INFO - Job 1592: Subtask wait_for_json
[2023-06-14T19:27:43.678+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:27:43.784+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:27:43.799+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:27:43.828+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:27:43.857+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:27:43.904+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:28:16.037+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:28:16.053+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:28:16.054+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:28:16.074+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:28:16.085+0000] {standard_task_runner.py:57} INFO - Started process 8974 to run task
[2023-06-14T19:28:16.093+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1595', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp4vunfe15']
[2023-06-14T19:28:16.096+0000] {standard_task_runner.py:85} INFO - Job 1595: Subtask wait_for_json
[2023-06-14T19:28:16.172+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:28:16.329+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:28:16.365+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:28:16.439+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:28:16.478+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:28:16.557+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:28:48.594+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:28:48.622+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:28:48.640+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:28:48.677+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:28:48.697+0000] {standard_task_runner.py:57} INFO - Started process 8993 to run task
[2023-06-14T19:28:48.725+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1598', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmprxz32nar']
[2023-06-14T19:28:48.732+0000] {standard_task_runner.py:85} INFO - Job 1598: Subtask wait_for_json
[2023-06-14T19:28:48.814+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:28:48.920+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:28:48.936+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:28:48.963+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:28:49.011+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:28:49.057+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:29:21.183+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:29:21.200+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:29:21.202+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:29:21.228+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:29:21.239+0000] {standard_task_runner.py:57} INFO - Started process 9011 to run task
[2023-06-14T19:29:21.247+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1601', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp0wvf27d3']
[2023-06-14T19:29:21.252+0000] {standard_task_runner.py:85} INFO - Job 1601: Subtask wait_for_json
[2023-06-14T19:29:21.398+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:29:21.562+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:29:21.580+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:29:21.610+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:29:21.639+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:29:21.679+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:29:53.498+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:29:53.522+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:29:53.524+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:29:53.561+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:29:53.577+0000] {standard_task_runner.py:57} INFO - Started process 9028 to run task
[2023-06-14T19:29:53.596+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1604', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp7zw462ep']
[2023-06-14T19:29:53.605+0000] {standard_task_runner.py:85} INFO - Job 1604: Subtask wait_for_json
[2023-06-14T19:29:53.720+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:29:53.936+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:29:53.979+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:29:54.015+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:29:54.058+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:29:54.110+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:30:36.254+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:30:36.277+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:30:36.279+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:30:36.334+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:30:36.355+0000] {standard_task_runner.py:57} INFO - Started process 9046 to run task
[2023-06-14T19:30:36.404+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1607', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpf1zkgpsx']
[2023-06-14T19:30:36.423+0000] {standard_task_runner.py:85} INFO - Job 1607: Subtask wait_for_json
[2023-06-14T19:30:36.709+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:30:37.074+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:30:37.097+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:30:37.171+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:30:37.248+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:30:37.310+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:31:29.165+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:31:29.267+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:31:29.269+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:31:29.341+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:31:29.367+0000] {standard_task_runner.py:57} INFO - Started process 9076 to run task
[2023-06-14T19:31:29.547+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1611', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp57k4bo27']
[2023-06-14T19:31:29.594+0000] {standard_task_runner.py:85} INFO - Job 1611: Subtask wait_for_json
[2023-06-14T19:31:30.387+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:31:30.851+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:31:30.942+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c17a200>
[2023-06-14T19:31:31.066+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:31:31.168+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:31:31.421+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:32:04.418+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:32:04.438+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:32:04.442+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:32:04.555+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:32:04.583+0000] {standard_task_runner.py:57} INFO - Started process 9098 to run task
[2023-06-14T19:32:04.615+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1615', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpqa1qt30r']
[2023-06-14T19:32:04.639+0000] {standard_task_runner.py:85} INFO - Job 1615: Subtask wait_for_json
[2023-06-14T19:32:06.035+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:32:32.757+0000] {job.py:216} ERROR - Job heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/jobs/job.py", line 187, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3062, in merge
    _resolve_conflict_map=_resolve_conflict_map,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3140, in _merge
    options=options,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2861, in get
    execution_options=execution_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2979, in _get_impl
    load_options=load_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/loading.py", line 534, in load_on_pk_identity
    bind_arguments=bind_arguments,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 1556, in _connection_for_bind
    engine, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3320, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3399, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3370, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2204, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 3366, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[2023-06-14T19:32:35.582+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:32:35.743+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:32:36.137+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:32:36.329+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:32:36.457+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:33:07.962+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:33:08.004+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:33:08.009+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:33:08.061+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:33:08.080+0000] {standard_task_runner.py:57} INFO - Started process 9118 to run task
[2023-06-14T19:33:08.118+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1618', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpwk1crt71']
[2023-06-14T19:33:08.142+0000] {standard_task_runner.py:85} INFO - Job 1618: Subtask wait_for_json
[2023-06-14T19:33:08.328+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:33:08.504+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:33:08.562+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:33:08.604+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:33:08.672+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:33:08.762+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:33:42.654+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:33:42.684+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:33:42.687+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:33:42.725+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:33:42.734+0000] {standard_task_runner.py:57} INFO - Started process 9141 to run task
[2023-06-14T19:33:42.772+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1624', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpytcjypcx']
[2023-06-14T19:33:42.778+0000] {standard_task_runner.py:85} INFO - Job 1624: Subtask wait_for_json
[2023-06-14T19:33:42.964+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:33:43.431+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:33:43.516+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:33:43.625+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:33:43.702+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:33:43.814+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:34:16.935+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:34:17.051+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:34:17.052+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:34:17.249+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:34:17.274+0000] {standard_task_runner.py:57} INFO - Started process 9162 to run task
[2023-06-14T19:34:17.295+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1628', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp5uyas2d0']
[2023-06-14T19:34:17.307+0000] {standard_task_runner.py:85} INFO - Job 1628: Subtask wait_for_json
[2023-06-14T19:34:17.506+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:34:17.779+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:34:17.835+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c17a200>
[2023-06-14T19:34:17.894+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:34:17.940+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:34:18.003+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:34:54.122+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:34:54.256+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:34:54.266+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:34:54.443+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:34:54.467+0000] {standard_task_runner.py:57} INFO - Started process 9189 to run task
[2023-06-14T19:34:54.497+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1632', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpqw9wvby1']
[2023-06-14T19:34:54.506+0000] {standard_task_runner.py:85} INFO - Job 1632: Subtask wait_for_json
[2023-06-14T19:34:55.022+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:34:55.482+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:34:55.549+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c17a200>
[2023-06-14T19:34:55.592+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:34:55.644+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:34:55.706+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:35:28.243+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:35:28.267+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:35:28.268+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:35:28.299+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:35:28.327+0000] {standard_task_runner.py:57} INFO - Started process 9201 to run task
[2023-06-14T19:35:28.377+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1635', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp1m4fgb28']
[2023-06-14T19:35:28.425+0000] {standard_task_runner.py:85} INFO - Job 1635: Subtask wait_for_json
[2023-06-14T19:35:28.642+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:35:29.021+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:35:29.054+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:35:29.100+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:35:29.142+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:35:29.241+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:36:01.488+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:36:01.525+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:36:01.527+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:36:01.581+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:36:01.600+0000] {standard_task_runner.py:57} INFO - Started process 9222 to run task
[2023-06-14T19:36:01.621+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1638', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpf1dfe5dc']
[2023-06-14T19:36:01.639+0000] {standard_task_runner.py:85} INFO - Job 1638: Subtask wait_for_json
[2023-06-14T19:36:01.780+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:36:01.992+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:36:02.020+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c18c3b0>
[2023-06-14T19:36:02.077+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:36:02.160+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:36:02.252+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:36:33.793+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:36:33.809+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:36:33.810+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:36:33.831+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:36:33.841+0000] {standard_task_runner.py:57} INFO - Started process 9238 to run task
[2023-06-14T19:36:33.851+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1642', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpkllbegqw']
[2023-06-14T19:36:33.856+0000] {standard_task_runner.py:85} INFO - Job 1642: Subtask wait_for_json
[2023-06-14T19:36:33.924+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:36:34.048+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:36:34.071+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:36:34.121+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:36:34.183+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:36:34.318+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:37:06.136+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:37:06.159+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:37:06.162+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:37:06.196+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:37:06.216+0000] {standard_task_runner.py:57} INFO - Started process 9258 to run task
[2023-06-14T19:37:06.239+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1646', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpkgiff8r4']
[2023-06-14T19:37:06.247+0000] {standard_task_runner.py:85} INFO - Job 1646: Subtask wait_for_json
[2023-06-14T19:37:06.371+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:37:06.504+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:37:06.524+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:37:06.588+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:37:06.608+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:37:06.648+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:37:38.409+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:37:38.426+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:37:38.428+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:37:38.449+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:37:38.457+0000] {standard_task_runner.py:57} INFO - Started process 9280 to run task
[2023-06-14T19:37:38.464+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1650', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpyfo9lru_']
[2023-06-14T19:37:38.468+0000] {standard_task_runner.py:85} INFO - Job 1650: Subtask wait_for_json
[2023-06-14T19:37:38.539+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:37:38.642+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:37:38.658+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:37:38.686+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:37:38.718+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:37:38.777+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:38:09.953+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:38:09.967+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:38:09.969+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:38:09.988+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:38:09.997+0000] {standard_task_runner.py:57} INFO - Started process 9300 to run task
[2023-06-14T19:38:10.004+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1654', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpo8oftld_']
[2023-06-14T19:38:10.008+0000] {standard_task_runner.py:85} INFO - Job 1654: Subtask wait_for_json
[2023-06-14T19:38:10.080+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:38:10.181+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:38:10.198+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:38:10.226+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:38:10.256+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:38:10.340+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:38:41.812+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:38:41.832+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:38:41.833+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:38:41.894+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:38:41.908+0000] {standard_task_runner.py:57} INFO - Started process 9321 to run task
[2023-06-14T19:38:41.917+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1658', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp7b23q6gi']
[2023-06-14T19:38:41.923+0000] {standard_task_runner.py:85} INFO - Job 1658: Subtask wait_for_json
[2023-06-14T19:38:41.995+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:38:42.095+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:38:42.111+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:38:42.138+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:38:42.185+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:38:42.228+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:39:13.826+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:39:13.839+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:39:13.840+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:39:13.859+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:39:13.870+0000] {standard_task_runner.py:57} INFO - Started process 9342 to run task
[2023-06-14T19:39:13.877+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1662', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmposttmdao']
[2023-06-14T19:39:13.880+0000] {standard_task_runner.py:85} INFO - Job 1662: Subtask wait_for_json
[2023-06-14T19:39:13.951+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:39:14.113+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:39:14.133+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:39:14.203+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:39:14.253+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:39:14.297+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:39:46.321+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:39:46.344+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:39:46.346+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:39:46.373+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:39:46.386+0000] {standard_task_runner.py:57} INFO - Started process 9363 to run task
[2023-06-14T19:39:46.397+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1666', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpk7mjiy18']
[2023-06-14T19:39:46.404+0000] {standard_task_runner.py:85} INFO - Job 1666: Subtask wait_for_json
[2023-06-14T19:39:46.487+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:39:46.606+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:39:46.624+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:39:46.651+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:39:46.696+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:39:46.743+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:40:17.716+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:40:17.732+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:40:17.734+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:40:17.752+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:40:17.761+0000] {standard_task_runner.py:57} INFO - Started process 9384 to run task
[2023-06-14T19:40:17.767+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1670', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmphmj_ml8y']
[2023-06-14T19:40:17.771+0000] {standard_task_runner.py:85} INFO - Job 1670: Subtask wait_for_json
[2023-06-14T19:40:17.838+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:40:17.949+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:40:17.967+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:40:18.076+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:40:18.101+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:40:18.144+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:40:49.875+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:40:49.890+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:40:49.891+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:40:49.910+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:40:49.919+0000] {standard_task_runner.py:57} INFO - Started process 9405 to run task
[2023-06-14T19:40:49.925+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1674', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmpospsmcnz']
[2023-06-14T19:40:49.930+0000] {standard_task_runner.py:85} INFO - Job 1674: Subtask wait_for_json
[2023-06-14T19:40:49.998+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:40:50.102+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:40:50.118+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:40:50.145+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:40:50.180+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:40:50.284+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:41:21.945+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:41:21.960+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:41:21.961+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:41:21.982+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:41:21.990+0000] {standard_task_runner.py:57} INFO - Started process 9425 to run task
[2023-06-14T19:41:21.997+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1678', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp_uevwb5m']
[2023-06-14T19:41:22.000+0000] {standard_task_runner.py:85} INFO - Job 1678: Subtask wait_for_json
[2023-06-14T19:41:22.069+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:41:22.168+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:41:22.183+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:41:22.209+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:41:22.254+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:41:22.297+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:41:53.539+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:41:53.558+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:41:53.560+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:41:53.583+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:41:53.592+0000] {standard_task_runner.py:57} INFO - Started process 9446 to run task
[2023-06-14T19:41:53.602+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1682', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp5i2e1ia_']
[2023-06-14T19:41:53.606+0000] {standard_task_runner.py:85} INFO - Job 1682: Subtask wait_for_json
[2023-06-14T19:41:53.698+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:41:53.868+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:41:53.900+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:41:53.956+0000] {taskinstance.py:1784} INFO - Rescheduling task, marking task as UP_FOR_RESCHEDULE
[2023-06-14T19:41:54.017+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:41:54.213+0000] {taskinstance.py:2651} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2023-06-14T19:42:25.944+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:42:25.965+0000] {taskinstance.py:1103} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [queued]>
[2023-06-14T19:42:25.967+0000] {taskinstance.py:1308} INFO - Starting attempt 1 of 1
[2023-06-14T19:42:25.998+0000] {taskinstance.py:1327} INFO - Executing <Task(PythonSensor): wait_for_json> on 2023-06-14 19:25:30.550102+00:00
[2023-06-14T19:42:26.023+0000] {standard_task_runner.py:57} INFO - Started process 9466 to run task
[2023-06-14T19:42:26.034+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'get_university_api_send_psql', 'wait_for_json', 'manual__2023-06-14T19:25:30.550102+00:00', '--job-id', '1686', '--raw', '--subdir', 'DAGS_FOLDER/data-university-from-api-dag/data_university_from_api_dag.py', '--cfg-path', '/tmp/tmp2gc159dk']
[2023-06-14T19:42:26.040+0000] {standard_task_runner.py:85} INFO - Job 1686: Subtask wait_for_json
[2023-06-14T19:42:26.123+0000] {task_command.py:410} INFO - Running <TaskInstance: get_university_api_send_psql.wait_for_json manual__2023-06-14T19:25:30.550102+00:00 [running]> on host cd01a659cc96
[2023-06-14T19:42:26.294+0000] {taskinstance.py:1547} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='get_university_api_send_psql' AIRFLOW_CTX_TASK_ID='wait_for_json' AIRFLOW_CTX_EXECUTION_DATE='2023-06-14T19:25:30.550102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-06-14T19:25:30.550102+00:00'
[2023-06-14T19:42:26.331+0000] {python.py:72} INFO - Poking callable: <function _wait_for_json at 0x7fb93c12b440>
[2023-06-14T19:42:26.340+0000] {base.py:255} INFO - Success criteria met. Exiting.
[2023-06-14T19:42:26.369+0000] {taskinstance.py:1350} INFO - Marking task as SUCCESS. dag_id=get_university_api_send_psql, task_id=wait_for_json, execution_date=20230614T192530, start_date=20230614T194225, end_date=20230614T194226
[2023-06-14T19:42:26.405+0000] {local_task_job_runner.py:225} INFO - Task exited with return code 0
[2023-06-14T19:42:26.464+0000] {taskinstance.py:2651} INFO - 1 downstream tasks scheduled from follow-on schedule check
